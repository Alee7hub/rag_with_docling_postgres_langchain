{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a1a1e0",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f75e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from docling.document_converter import DocumentConverter\n",
    "from langchain_core.documents import Document\n",
    "from docling.chunking import HybridChunker\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab3f7d4",
   "metadata": {},
   "source": [
    "### Process all documents from a directory and save the resulted chunks to a list as langchain documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942d37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_documents_to_langchain(documents_dir: str, max_tokens: int = 512):\n",
    "    \"\"\"Process multiple documents and return a list of LangChain Document objects.\n",
    "    \n",
    "    Docling automatically handles all supported file formats (.pdf, .md, .docx, .html, .txt, etc.)\n",
    "    \n",
    "    Args:\n",
    "        documents_dir: Directory containing documents to process\n",
    "        max_tokens: Maximum tokens per chunk\n",
    "        \n",
    "    Returns:\n",
    "        List of LangChain Document objects with page_content and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"BATCH HYBRID CHUNKING - TO LANGCHAIN DOCUMENTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get all files from directory (excluding directories)\n",
    "    documents_path = Path(documents_dir)\n",
    "    all_files = [f for f in documents_path.iterdir() if f.is_file()]\n",
    "    all_files = sorted(all_files)  # Sort for consistent ordering\n",
    "    \n",
    "    if not all_files:\n",
    "        print(f\"\\nâœ— No files found in {documents_dir}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\nFound {len(all_files)} documents to process\")\n",
    "    print(f\"Max tokens per chunk: {max_tokens}\\n\")\n",
    "    \n",
    "    # Initialize tokenizer once (reuse for all documents)\n",
    "    print(\"Initializing tokenizer...\")\n",
    "    model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "    # Create chunker once (reuse for all documents)\n",
    "    chunker = HybridChunker(\n",
    "        tokenizer=tokenizer,\n",
    "        max_tokens=max_tokens,\n",
    "        merge_peers=True\n",
    "    )\n",
    "    \n",
    "    langchain_documents = []\n",
    "    total_chunks = 0\n",
    "    successful_docs = 0\n",
    "    failed_docs = []\n",
    "    \n",
    "    # Process each document\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            print(f\"\\nðŸ“„ Processing: {file_path.name}\")\n",
    "            \n",
    "            # Convert document\n",
    "            print(\"   Converting document...\")\n",
    "            converter = DocumentConverter()\n",
    "            result = converter.convert(str(file_path))\n",
    "            doc = result.document\n",
    "            \n",
    "            # Generate chunks\n",
    "            print(\"   Generating chunks...\")\n",
    "            chunk_iter = chunker.chunk(dl_doc=doc)\n",
    "            chunks = list(chunk_iter)\n",
    "            \n",
    "            print(f\"   Creating {len(chunks)} LangChain Document objects...\")\n",
    "            \n",
    "            # Convert each chunk to LangChain Document\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                # Use contextualize to preserve headings and metadata\n",
    "                contextualized_text = chunker.contextualize(chunk=chunk)\n",
    "                \n",
    "                # Create LangChain Document with metadata\n",
    "                langchain_doc = Document(\n",
    "                    page_content=contextualized_text,\n",
    "                    metadata={\n",
    "                        \"source\": str(file_path),\n",
    "                        \"source_name\": file_path.name,\n",
    "                        \"chunk_index\": total_chunks + i,\n",
    "                        \"document_chunk_index\": i,\n",
    "                        \"total_chunks_in_document\": len(chunks)\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                langchain_documents.append(langchain_doc)\n",
    "            \n",
    "            total_chunks += len(chunks)\n",
    "            successful_docs += 1\n",
    "            print(f\"   âœ“ Success! Total chunks so far: {total_chunks}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âœ— Error processing {file_path.name}: {e}\")\n",
    "            failed_docs.append(file_path.name)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ“ Successfully processed: {successful_docs}/{len(all_files)} documents\")\n",
    "    print(f\"âœ“ Total LangChain Documents created: {len(langchain_documents)}\")\n",
    "    \n",
    "    if failed_docs:\n",
    "        print(f\"\\nâœ— Failed documents ({len(failed_docs)}):\")\n",
    "        for doc in failed_docs:\n",
    "            print(f\"   - {doc}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"LANGCHAIN DOCUMENTS READY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"âœ“ Each chunk is a LangChain Document object\")\n",
    "    print(\"âœ“ page_content: Contextualized chunk text with headings\")\n",
    "    print(\"âœ“ metadata: source, source_name, chunk_index, etc.\")\n",
    "    print(\"âœ“ Ready for vector store ingestion (Chroma, FAISS, Pinecone, etc.)\")\n",
    "    \n",
    "    return langchain_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a68df9",
   "metadata": {},
   "source": [
    "### usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1097fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BATCH HYBRID CHUNKING - TO LANGCHAIN DOCUMENTS\n",
      "============================================================\n",
      "\n",
      "Found 9 documents to process\n",
      "Max tokens per chunk: 512\n",
      "\n",
      "Initializing tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 11:44:00,542 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ Processing: client-review-globalfinance.pdf\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 11:44:03,294 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:44:03,297 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-11-01 11:44:03,322 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-01 11:44:03,326 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-11-01 11:44:03,388 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-01 11:44:03,402 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-11-01 11:44:03,586 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-11-01 11:44:03,587 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-11-01 11:44:04,471 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:04,505 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:04,576 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:04,577 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:04,921 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:04,934 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:04,935 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:05,026 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:05,119 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:44:05,120 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-11-01 11:44:05,386 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-11-01 11:44:05,398 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:44:06,764 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:44:07,781 - INFO - Processing document client-review-globalfinance.pdf\n",
      "2025-11-01 11:45:11,392 - INFO - Finished converting document client-review-globalfinance.pdf in 70.90 sec.\n",
      "2025-11-01 11:45:11,575 - INFO - detected formats: [<InputFormat.MD: 'md'>]\n",
      "2025-11-01 11:45:11,576 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:45:11,577 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-11-01 11:45:11,577 - INFO - Processing document company-overview.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 24 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 24\n",
      "\n",
      "ðŸ“„ Processing: company-overview.md\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 11:45:11,917 - INFO - Finished converting document company-overview.md in 0.36 sec.\n",
      "2025-11-01 11:45:11,979 - INFO - detected formats: [<InputFormat.MD: 'md'>]\n",
      "2025-11-01 11:45:11,980 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:45:11,981 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-11-01 11:45:11,982 - INFO - Processing document implementation-playbook.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 8 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 32\n",
      "\n",
      "ðŸ“„ Processing: implementation-playbook.md\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 11:45:12,938 - INFO - Finished converting document implementation-playbook.md in 0.97 sec.\n",
      "2025-11-01 11:45:13,115 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-01 11:45:13,119 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:45:13,119 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-11-01 11:45:13,121 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-11-01 11:45:13,123 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-11-01 11:45:13,124 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:13,142 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 27 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 59\n",
      "\n",
      "ðŸ“„ Processing: meeting-notes-2025-01-08.docx\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2025-11-01 11:45:13,181 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:13,182 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:13,413 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:13,416 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:13,417 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:13,504 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:13,574 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:13,575 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-11-01 11:45:13,840 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-11-01 11:45:13,841 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:45:15,080 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:45:15,576 - INFO - Processing document meeting-notes-2025-01-08.docx\n",
      "2025-11-01 11:45:51,161 - INFO - Finished converting document meeting-notes-2025-01-08.docx in 38.07 sec.\n",
      "2025-11-01 11:45:51,288 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-01 11:45:51,291 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:45:51,292 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-11-01 11:45:51,293 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-11-01 11:45:51,294 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-11-01 11:45:51,295 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:51,318 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:51,359 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:51,360 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 23 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 82\n",
      "\n",
      "ðŸ“„ Processing: meeting-notes-2025-01-15.docx\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2025-11-01 11:45:51,584 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:51,588 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:51,589 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:51,697 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:51,772 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:45:51,773 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-11-01 11:45:52,042 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-11-01 11:45:52,043 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:45:53,073 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:45:53,529 - INFO - Processing document meeting-notes-2025-01-15.docx\n",
      "2025-11-01 11:46:17,035 - INFO - Finished converting document meeting-notes-2025-01-15.docx in 25.76 sec.\n",
      "2025-11-01 11:46:17,188 - INFO - detected formats: [<InputFormat.MD: 'md'>]\n",
      "2025-11-01 11:46:17,189 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:46:17,190 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-11-01 11:46:17,191 - INFO - Processing document mission-and-goals.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 23 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 105\n",
      "\n",
      "ðŸ“„ Processing: mission-and-goals.md\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 11:46:17,989 - INFO - Finished converting document mission-and-goals.md in 0.82 sec.\n",
      "2025-11-01 11:46:18,154 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-01 11:46:18,158 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:46:18,159 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-11-01 11:46:18,160 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-11-01 11:46:18,162 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-11-01 11:46:18,164 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:18,190 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 16 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 121\n",
      "\n",
      "ðŸ“„ Processing: q4-2024-business-review.pdf\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2025-11-01 11:46:18,237 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:18,238 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:18,545 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:18,550 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:18,551 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:18,672 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:18,754 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:18,755 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-11-01 11:46:19,036 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-11-01 11:46:19,037 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:46:20,256 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:46:20,835 - INFO - Processing document q4-2024-business-review.pdf\n",
      "2025-11-01 11:46:46,951 - INFO - Finished converting document q4-2024-business-review.pdf in 28.82 sec.\n",
      "2025-11-01 11:46:47,093 - INFO - detected formats: [<InputFormat.MD: 'md'>]\n",
      "2025-11-01 11:46:47,094 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:46:47,095 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-11-01 11:46:47,096 - INFO - Processing document team-handbook.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 25 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 146\n",
      "\n",
      "ðŸ“„ Processing: team-handbook.md\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 11:46:47,803 - INFO - Finished converting document team-handbook.md in 0.73 sec.\n",
      "2025-11-01 11:46:47,929 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-01 11:46:47,932 - INFO - Going to convert document batch...\n",
      "2025-11-01 11:46:47,933 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-11-01 11:46:47,935 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-11-01 11:46:47,936 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-11-01 11:46:47,937 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:47,959 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:48,000 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:48,001 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 21 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 167\n",
      "\n",
      "ðŸ“„ Processing: technical-architecture-guide.pdf\n",
      "   Converting document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2025-11-01 11:46:48,472 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:48,475 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:48,476 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:48,576 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:48,666 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-01 11:46:48,667 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-11-01 11:46:48,943 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-11-01 11:46:48,944 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:46:50,325 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-01 11:46:50,835 - INFO - Processing document technical-architecture-guide.pdf\n",
      "2025-11-01 11:47:49,025 - INFO - Finished converting document technical-architecture-guide.pdf in 61.12 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generating chunks...\n",
      "   Creating 23 LangChain Document objects...\n",
      "   âœ“ Success! Total chunks so far: 190\n",
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE\n",
      "============================================================\n",
      "âœ“ Successfully processed: 9/9 documents\n",
      "âœ“ Total LangChain Documents created: 190\n",
      "\n",
      "============================================================\n",
      "LANGCHAIN DOCUMENTS READY\n",
      "============================================================\n",
      "âœ“ Each chunk is a LangChain Document object\n",
      "âœ“ page_content: Contextualized chunk text with headings\n",
      "âœ“ metadata: source, source_name, chunk_index, etc.\n",
      "âœ“ Ready for vector store ingestion (Chroma, FAISS, Pinecone, etc.)\n"
     ]
    }
   ],
   "source": [
    "raw_documents_dir = \"../documents/raw\"\n",
    "all_chunks = process_documents_to_langchain(documents_dir=raw_documents_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd0e9b",
   "metadata": {},
   "source": [
    "### Vector storage -> Postgres/pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "448f7fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 12:36:13,804 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['f886f464-c690-48a9-986a-2851f7c68b36',\n",
       " 'a1fff7a1-3dd9-4182-918f-3661de49a538',\n",
       " 'de8b9dc8-514b-481a-8914-80b4a140d666',\n",
       " '59d2667a-a581-4024-aaf9-a317961a889b',\n",
       " 'e1aef5f8-9e42-4a4c-8aa0-efc52da148ce',\n",
       " '5bd5090f-79d5-42ea-817c-463dc66437f0',\n",
       " '64e8f544-fb1b-4be9-adfd-d0c0f547c49f',\n",
       " '5f90edc4-21b4-423b-bae2-21ad8459ba4b',\n",
       " 'f7295db2-a334-4a0d-b7f9-ac9427a3ae47',\n",
       " '6725805f-5f16-4cd2-b07e-7da44b89c9db',\n",
       " 'dd79354e-77e1-4600-b8d2-826dd89ac297',\n",
       " 'd90f574d-be22-4ba3-b590-0d9b6090af82',\n",
       " '3fa6d380-21d9-40ab-a812-a0e3b334ba42',\n",
       " 'ce6010ec-e33b-4e0b-8e0e-c4eb7eb3cd5b',\n",
       " '90f7a6f3-83d2-4320-916d-c50c40e8fc8a',\n",
       " '4f488732-c840-49f3-bfea-9a72ea760885',\n",
       " '44a15954-81d5-4f49-aae6-4c16a6542041',\n",
       " '2fdbb43c-41f0-4eab-b7ff-2ff38a9de1eb',\n",
       " 'd6c0beec-f415-4cdc-9432-cfb88e3d412c',\n",
       " 'a8a40405-58d4-4cc9-a352-bae5c7da2217',\n",
       " 'd08e5b19-1785-4148-b500-bc4e80af0e4e',\n",
       " '274114e3-74fe-40a4-bac9-81f2722f3502',\n",
       " 'd0cc6c2f-a524-44cc-aff1-6209a27cd1e3',\n",
       " 'cbf2f045-af28-4a80-a443-1d97c42c1446',\n",
       " '7c68e686-c53d-483b-988a-f73158d365eb',\n",
       " 'ca7e310d-699d-4c09-babe-274cf8392179',\n",
       " '2b258017-60c0-4ccc-a535-4d1479122d6b',\n",
       " '7f1368a5-de26-474d-b520-e141564101f2',\n",
       " '21477445-6def-43be-8c89-476bfb640d3a',\n",
       " 'a92f6ea2-30fa-4a6b-ad48-b4fe67f05889',\n",
       " '85a6c8b1-d415-4051-9a9b-fe4c50f04420',\n",
       " '4a402d3f-6e98-440c-9b38-811504758253',\n",
       " '3c37043a-47a4-4623-8652-c16b9ee13fae',\n",
       " '707ad388-aa74-4ec1-8024-c0a90f1432b2',\n",
       " '1ee65c19-caec-4f18-9000-41435769187c',\n",
       " 'ac8d0895-6262-44a3-84b8-991840476bc7',\n",
       " '47f739fc-49be-46f7-b935-e61a6713d9a2',\n",
       " 'c1534466-7bdd-40ab-b873-e6dcd664deaa',\n",
       " 'cadb7b0a-c0fa-4076-9a71-6f01c63545dc',\n",
       " '8e5b2cf9-db50-47e4-8b5c-32b202481232',\n",
       " '7655a557-f0f7-48de-b70e-9d8c6a0c1631',\n",
       " '57336578-9417-4529-b507-c06e59efb7b1',\n",
       " '68404d78-4898-4def-9b9e-6106dfd862c4',\n",
       " 'e46a07e9-e6c8-4039-b597-b04258008c3e',\n",
       " 'd9bdc6eb-c4bd-4925-92bf-58c7d70f5aba',\n",
       " 'f6fc6861-bcec-4912-af88-7275af0b2e5f',\n",
       " 'c5a94972-1f3b-4358-b3e8-4cd4badc3521',\n",
       " '022199b1-0d31-4b82-a436-b5befc8014a5',\n",
       " '6d71e06d-af63-4d02-a6f7-b3d6e2bf6fdd',\n",
       " 'e13184d2-1c8c-4c0b-a826-a01af833abcc',\n",
       " '75dc91d3-d4b1-4a13-b589-fbc6aefc24cb',\n",
       " '58214f50-05ba-47fb-b455-eeda8d891134',\n",
       " 'c9878728-ed50-4400-8e1f-3c70f5f7f876',\n",
       " 'cc48ef74-df03-435f-9500-81156a614c5d',\n",
       " 'd9f83a67-afb1-44fb-a9ba-144aa5b09e35',\n",
       " '1b97af36-a185-4904-9a14-e33407709171',\n",
       " 'fcc0ea76-e3cb-42f2-a2cb-48bce9b68d07',\n",
       " 'ca17c481-4392-4433-862f-331d6db9ad62',\n",
       " 'e027e6b4-e32c-4724-b6f5-d4d9a61eb641',\n",
       " 'a13c51ab-c8ff-486c-a25d-3cbf71ca0718',\n",
       " 'b3fd32bb-f645-4bbe-9713-2edd888b42de',\n",
       " 'e7e211ad-85ad-42c0-9d99-178ca6015622',\n",
       " 'e940fff6-76fa-425f-b91f-0cfa2e510858',\n",
       " '3133b55d-deae-44df-869a-03f9094f1892',\n",
       " '8fbe5b1c-28e7-45eb-aa06-20a92bb5d3ff',\n",
       " 'ad652415-f4be-4865-b345-06000e3c4c6f',\n",
       " '1fa2a1c6-7b37-4b86-8c52-5f83182006bf',\n",
       " 'bd1a18c0-74e6-46d9-8a30-3520fef13499',\n",
       " '4a838b64-d453-49e5-8859-4c6c2fcb1344',\n",
       " '522e004e-6320-4c67-b23f-13576df32ece',\n",
       " '5eaa1ef2-8011-49fc-bcbe-cf7fe5e6b674',\n",
       " '7e4d633f-0159-41f5-8c02-532e9b376407',\n",
       " 'a2e4c54a-bdf1-4cae-acd2-7db563958322',\n",
       " 'eb1ac42d-7ef2-45f1-bfb2-2ead833a67c7',\n",
       " '553e8bff-9f94-46db-a85f-8ff9775b6a09',\n",
       " 'a96c23a8-0f9f-4b85-af75-e37e88bba88d',\n",
       " 'e47bd70d-4c10-4ee2-8fd8-c9ecad008995',\n",
       " '32f88dcf-0ade-40c9-a26b-3ed3f8a5ddd8',\n",
       " '1a8cd3af-2235-44cf-a668-8c3a11da69dd',\n",
       " '1a1f866a-3990-4664-8e10-2289c7ab0d19',\n",
       " 'f87806e0-3e33-4dc1-a1c4-7109f06a11e2',\n",
       " '6e2fe770-9e8b-4a8e-b246-3e6ac679ca3f',\n",
       " '203bc9be-2fad-4d72-8655-e23490d51276',\n",
       " 'a9ed3cd4-5e82-44a8-a59e-3b3ba6445456',\n",
       " '734b59ac-9a95-4f8b-bc11-cfddc5049b4c',\n",
       " '0609c347-fb7e-4d49-9e4d-8329e6bf2247',\n",
       " '094d3e1c-6da7-41a8-ab53-ffff079e89f0',\n",
       " '303a423d-85ce-4997-8089-19bc9b323016',\n",
       " '9e54a5c8-2d53-4839-ba36-0a650daf1e97',\n",
       " 'dafd3e84-b50a-4afe-8b61-8669ef1ac2b1',\n",
       " 'bb7a5447-9ab1-4043-8334-6e3c64b46593',\n",
       " '855ef644-e563-4a49-aa24-26e321bf14e0',\n",
       " '66802f33-c2d7-422c-9912-a88a50ee8aa9',\n",
       " '16609beb-e441-4d77-b187-2e92ca0bf1ea',\n",
       " 'db7d000d-5440-4e02-b974-a691fa71196c',\n",
       " 'd9ed77f2-28c3-4f40-85ac-a70d8a2161f7',\n",
       " '9c07e177-ab31-47f2-b577-a9095c171886',\n",
       " '45d05c20-bbf6-437f-b11f-b17829478611',\n",
       " 'd8c7d51c-7024-45c3-b42b-49d192415d67',\n",
       " '815ded48-330a-492a-9de2-879ea1b10e8f',\n",
       " '58240a53-b3eb-48ec-933e-d7668e74c6f1',\n",
       " '333b9492-0018-43a6-9da2-883b0c0a1981',\n",
       " 'bed4d3d6-08e7-4524-9645-57e6e1aa6975',\n",
       " '3f74d2f4-2d9d-4cc0-b397-5ba8ef8db85e',\n",
       " '1caa0ab0-017c-4c79-a361-9c4c5331ea0a',\n",
       " '0fb2d6df-958b-48bc-bdb2-7f01f48e15dc',\n",
       " 'abd0c83a-ca89-4fa5-9f23-db6649ce96ea',\n",
       " '58866bc1-1396-4b99-bfbe-39c9ef79d61e',\n",
       " 'd680d7a8-ab17-4040-9ad5-af18d27536e1',\n",
       " 'c9290388-4447-48c1-8f53-610c053f0d62',\n",
       " 'ee5d1d31-e035-46fe-a001-69c24cc5938a',\n",
       " '3efd14f1-9252-4b1e-af01-20e3b0ad0f43',\n",
       " '7c0a8f04-f516-46cb-8a97-36d6b3634028',\n",
       " '55295477-a15a-406c-a748-a8b30cb11c39',\n",
       " 'bd66ac37-996a-4fc1-ac24-b3a43e1aa792',\n",
       " '3ed37034-1504-498f-bbfd-23f7fb3316ae',\n",
       " 'ad09ad60-6cef-4470-b539-cdd05203b932',\n",
       " '363c5cf8-fdc9-48d0-bcfa-35fcd51a000e',\n",
       " 'f79a3897-20f6-4f32-b093-1dc707de7043',\n",
       " 'a61ed731-fb94-43b7-a3de-0bb5770a3d01',\n",
       " '98ac5cbd-8863-46bd-9558-4f796e6bdc6f',\n",
       " '4e1f3559-8dd3-4e06-99d3-5a74aff79fa8',\n",
       " '96851252-811e-4d3e-8062-a36eeaa2de2f',\n",
       " 'd5cb2ad1-7a95-4f76-94ba-858a7103ce1b',\n",
       " 'e5642cb2-5890-42b4-852e-20959faf6b39',\n",
       " 'be17e1e2-beee-4b11-8b0f-842783b38eb9',\n",
       " '5268bf45-4f7d-4bd6-808c-2fc00be9939c',\n",
       " 'b541d10e-7afa-49a4-988a-740593fed973',\n",
       " '3f254fb2-150a-4402-a382-6d1e8463511e',\n",
       " 'c12d179a-792a-48b4-b0f6-9f316e796a89',\n",
       " '162332bb-f707-4dab-a9fc-73f697188dce',\n",
       " '4edeb0c8-d05b-44bf-a138-8fe94c808365',\n",
       " '2482cf0a-e915-4b17-8d8b-9e59ee4f9b81',\n",
       " '999e5500-0f90-4a8a-b928-112b5a8467ee',\n",
       " '418a95a6-dccb-4679-b092-77761abbd93c',\n",
       " '17ea3fcf-4745-4495-affc-21b6d663d971',\n",
       " 'c2bc208d-ba23-437d-8408-d9521866ff70',\n",
       " '7a4e7d7d-7ed7-4e53-9b56-2355ba9ddad0',\n",
       " '79321896-3b75-4021-ac80-38b4f64432e0',\n",
       " 'a28c5829-836c-4564-b56f-6c420f2a7c3f',\n",
       " 'e79973a7-367b-4843-94f9-2a6073902890',\n",
       " '5b74e46b-b64f-48ad-bbf6-df09e8db7428',\n",
       " '87f38bc2-5596-4ba8-a451-c0a842255dcd',\n",
       " 'bdcf08f1-9117-47ab-b7a7-0d938e67803b',\n",
       " '89aa66d3-8a79-4b8c-8a34-917080556d2f',\n",
       " 'a7816689-86bb-442f-b5f4-1f9f59af7976',\n",
       " 'ff90cea7-5702-4bc7-bb3a-44a80d34d942',\n",
       " 'fd4b9735-9bae-4d21-a8f2-13538fc29f8d',\n",
       " '4360815b-5c85-41d5-b7d7-d29e7b174899',\n",
       " '74b4aadf-3240-47ad-8d9b-0f830ee1d409',\n",
       " 'ab03f1e2-02ca-4e81-be39-ced10477540e',\n",
       " 'c682bacc-30bb-41b9-92dc-de2896f66535',\n",
       " '515cc0ba-4fde-497e-a1c1-2146d23d6a8f',\n",
       " 'a2cd0b72-bf95-4cb3-8e59-6ab25d12977f',\n",
       " 'aec11dbd-2ea9-43c9-8771-045a22a52b8f',\n",
       " '142fed95-3e90-43b8-ad8d-28b970dde2a9',\n",
       " 'e0a52989-1b24-4ecf-9857-b2da69a29ee9',\n",
       " '9eb0d85f-d8e0-4cba-9e4f-d0e90342b2b1',\n",
       " '6f883135-73e4-484a-9fb5-771513d527a7',\n",
       " '025026a1-fc0c-42f3-a0bc-476f683bea09',\n",
       " '6e83b924-d6d8-44fc-9e78-0d75aeecfe6f',\n",
       " '9942254f-2968-41ee-8e36-749be7781611',\n",
       " '87e4fcf4-76db-4295-a8bb-aa502280ff8e',\n",
       " 'f822fc54-97c3-426f-9408-8bbd56a8bbce',\n",
       " '769d0820-2730-411b-9ec0-6a990089f83e',\n",
       " 'e6f3893c-31df-4653-aa0b-2bda17a7b52c',\n",
       " 'c71ae09c-6a76-4e5f-ba97-4c097bddbf3d',\n",
       " '3825c37e-399c-419e-920d-b6a4d923e774',\n",
       " 'e4976494-609b-4bbb-b931-44b678b34009',\n",
       " '4bcc4242-ae1f-4a6c-9aaa-5d55def79fdd',\n",
       " '5186851b-c050-44f8-b182-84023c4d91c3',\n",
       " '8e7afde4-f944-45da-989d-4ef8ded53347',\n",
       " '57be9acb-864b-4510-9767-620a04682f40',\n",
       " 'e84d90b3-699d-4805-8edd-e95b7ec0717e',\n",
       " '6c86d1f4-55be-4512-bcd7-d5c4e49dcdfb',\n",
       " '5feebdb8-f4a9-4636-bc4d-407021b10d77',\n",
       " 'bf5bc40c-7b26-4625-9a59-d2f5799dca62',\n",
       " '8738f718-7695-40ab-a663-c4bf9d2325d1',\n",
       " '62092dd2-3a16-4118-8ef9-5545b0ea080f',\n",
       " '3f332203-c9c3-430d-9564-6ef9ee8a1d43',\n",
       " '8687cfa2-8b43-4447-b060-b817b6320c53',\n",
       " '4df6f8bf-45ae-4c2f-97ec-0bad93b188f3',\n",
       " '9b60cd1e-4f40-49ff-9ac7-7daa499e5385',\n",
       " 'cc72bf03-1aea-4c1a-8ccc-71b162f120c4',\n",
       " 'f25ec887-430b-43fc-b182-3c06b51990ba',\n",
       " '3faef992-50be-46ac-89b6-e2cfeca62928',\n",
       " '33a2b2d5-fcb3-4918-a519-7c81f36d6b9f',\n",
       " '1bf9d9df-fb6b-4cfc-b841-257d30222b71',\n",
       " '8c429bd1-90fd-4e3d-903f-b62e6a765a8b',\n",
       " '516154c6-c9eb-43fe-9229-e9bb85f6751f']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import basics\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# initiate embeddings model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Connection string\n",
    "CONNECTION_STRING = \"postgresql+psycopg://raguser:ragpass@localhost:5555/ragdb\"\n",
    "\n",
    "# Initialize vector store\n",
    "vectorstore = PGVector(\n",
    "    connection=CONNECTION_STRING,\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"my_documents\",  # table name\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "vectorstore.add_documents(all_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c23b1",
   "metadata": {},
   "source": [
    "### Querying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c984579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 12:44:13,473 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Document:\n",
      "============================================================\n",
      "* Financial Targets Q1 2025\n",
      "Metric, 1 = Q4 2024 Actual. Metric, 2 = Q1 2025 Target. Metric, 3 = Growth. Revenue, 1 = $2.8M. Revenue, 2 = $3.4M. Revenue, 3 = +21%. New Clients, 1 = 14. New Clients, 2 = 16. New Clients, 3 = +14%. MRR, 1 = $890K. MRR, 2 = $1.15M. MRR, 3 = +29%. Gross Margin, 1 = 68%. Gross Margin, 2 = 70%. Gross Margin, 3 = +2pp [{'source': '..\\\\documents\\\\raw\\\\q4-2024-business-review.pdf', 'chunk_index': 144, 'source_name': 'q4-2024-business-review.pdf', 'document_chunk_index': 23, 'total_chunks_in_document': 25}]\n",
      "============================================================\n",
      "* Q1 Revenue Targets\n",
      "Product, 1 = Target New Customers. Product, 2 = Target MRR Growth. DocFlow AI, 1 = 12. DocFlow AI, 2 = $180K â†’$270K. ConversePro, 1 = 15. ConversePro, 2 = $0 â†’$225K. Custom Solutions, 1 = 8. Custom Solutions, 2 = $710K â†’$855K. Total, 1 = 35. Total, 2 = $890K â†’$1.35M [{'source': '..\\\\documents\\\\raw\\\\meeting-notes-2025-01-08.docx', 'chunk_index': 78, 'source_name': 'meeting-notes-2025-01-08.docx', 'document_chunk_index': 19, 'total_chunks_in_document': 23}]\n",
      "============================================================\n",
      "* Executive Summary\n",
      "Q4 2024 marked a transformative quarter for NeuralFlow AI, with record-breaking revenue growth and successful expansion into new market segments. Our strategic focus on enterprise clients and productized solutions yielded exceptional results, positioning us strongly for 2025. [{'source': '..\\\\documents\\\\raw\\\\q4-2024-business-review.pdf', 'chunk_index': 122, 'source_name': 'q4-2024-business-review.pdf', 'document_chunk_index': 1, 'total_chunks_in_document': 25}]\n",
      "============================================================\n",
      "* 3. Q1 2025 Product Roadmap\n",
      "Presented by:\n",
      "Michael Zhang\n",
      "Michael presented the finalized Q1 roadmap, incorporating today's decisions and customer feedback. [{'source': '..\\\\documents\\\\raw\\\\meeting-notes-2025-01-08.docx', 'chunk_index': 70, 'source_name': 'meeting-notes-2025-01-08.docx', 'document_chunk_index': 11, 'total_chunks_in_document': 23}]\n",
      "============================================================\n",
      "* Q1 2025 Priorities\n",
      "1. ConversePro Launch: Complete development and launch enterprise conversational AI platform (targeting March 2025)\n",
      "2. Scale Customer Success: Double customer success team and implement proactive engagement model\n",
      "3. Geographic Expansion: Establish New York office and hire East Coast sales team\n",
      "4. Partner Program: Launch formal partner program with 3 pilot system integrators\n",
      "5. SOC 2 Certification: Complete audit process and achieve certification [{'source': '..\\\\documents\\\\raw\\\\q4-2024-business-review.pdf', 'chunk_index': 143, 'source_name': 'q4-2024-business-review.pdf', 'document_chunk_index': 22, 'total_chunks_in_document': 25}]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Q1 2025 revenue target?\"\n",
    "\n",
    "# Query\n",
    "results = vectorstore.similarity_search(query, k=5)\n",
    "\n",
    "print(\"Retrieved Document:\")\n",
    "for doc in results:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3035b5",
   "metadata": {},
   "source": [
    "### Vector store -> Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f50b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 00:54:42,939 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-10-31 00:54:46,249 - INFO - HTTP Request: POST https://lrnjqowxzqyuqwdejzyk.supabase.co/rest/v1/documents?columns=%22metadata%22%2C%22id%22%2C%22embedding%22%2C%22content%22 \"HTTP/2 201 Created\"\n"
     ]
    }
   ],
   "source": [
    "# import basics\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import langchain\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# import supabase\n",
    "from supabase.client import Client, create_client\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()  \n",
    "\n",
    "# initiate supabase db\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "# initiate embeddings model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# store chunks in vector store\n",
    "vector_store = SupabaseVectorStore.from_documents(\n",
    "    all_chunks,\n",
    "    embeddings,\n",
    "    client=supabase,\n",
    "    table_name=\"documents\",\n",
    "    query_name=\"match_documents\",\n",
    "    chunk_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b83b70",
   "metadata": {},
   "source": [
    "### Querying supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b3e2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import Client, create_client\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# initiate embeddings model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# initiate supabase db\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "def query_vector_store(query: str, top_k: int = 5):\n",
    "    \"\"\"Query the Supabase vector store and return top_k similar documents.\n",
    "    \n",
    "    Args:\n",
    "        query: The input query string\n",
    "        top_k: Number of top similar documents to retrieve\n",
    "    \"\"\"\n",
    "    # 1. Embed the query\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "    # 2. Query the Supabase vector store\n",
    "    resp = (\n",
    "        supabase.rpc(\n",
    "            \"match_documents\",\n",
    "            {\n",
    "                \"query_embedding\": query_embedding,\n",
    "                \"match_count\": top_k,\n",
    "                \"match_threshold\": 0.0,\n",
    "                \"filter\": {}  # optional jsonb filter\n",
    "            }\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    # if resp.raise_when_api_error():\n",
    "    #     raise Exception(resp.raise_when_api_error())\n",
    "\n",
    "    matches = resp.data  # list of rows returned by the function\n",
    "    for m in matches:\n",
    "        # similarity is included in the returned row (see function)\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Document ID: {m['id']}\\nSimilarity: {m['similarity']}\\nMetadata: {m['metadata']}\\nContent: {m['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1bf42d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 14:18:05,033 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-10-31 14:18:05,732 - INFO - HTTP Request: POST https://lrnjqowxzqyuqwdejzyk.supabase.co/rest/v1/rpc/match_documents \"HTTP/2 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Document ID: 194e9e5e-3da1-4a77-97ac-0d0cb5c7b872\n",
      "Similarity: 0.615534534847961\n",
      "Metadata: {'source': '..\\\\documents\\\\raw\\\\client-review-globalfinance.pdf', 'chunk_index': 1, 'source_name': 'client-review-globalfinance.pdf', 'document_chunk_index': 1, 'total_chunks_in_document': 24}\n",
      "Content: Execuve Summary\n",
      "GlobalFinance Corp has achieved exceponal results in the first six months of our partnership. The DocFlow AI implementaon has exceeded all success metrics, delivering  $2.4M in annualized cost savings  and  94% reducon in loan applicaon processing me . Customer sasfacon scores have improved 37%, and the team has eliminated their applicaon backlog enrely.\n",
      "============================================================\n",
      "Document ID: 33bfd9c6-e422-4016-9de7-383b14cf65ea\n",
      "Similarity: 0.494471282425969\n",
      "Metadata: {'source': '..\\\\documents\\\\raw\\\\q4-2024-business-review.pdf', 'chunk_index': 131, 'source_name': 'q4-2024-business-review.pdf', 'document_chunk_index': 10, 'total_chunks_in_document': 25}\n",
      "Content: Case Study: GlobalFinance Corp\n",
      "Challenge: Manual processing of 15,000+ loan applications monthly, taking 3-5 days per application with high error rates.\n",
      "Solution: Deployed custom document processing AI with automated data extraction, validation, and risk scoring.\n",
      "============================================================\n",
      "Document ID: e889394f-1146-4b86-b5b8-7957209e0c96\n",
      "Similarity: 0.470417944813845\n",
      "Metadata: {'source': '..\\\\documents\\\\raw\\\\q4-2024-business-review.pdf', 'chunk_index': 124, 'source_name': 'q4-2024-business-review.pdf', 'document_chunk_index': 3, 'total_chunks_in_document': 25}\n",
      "Content: Financial Performance\n",
      "Our financial performance exceeded targets across all key metrics. The emphasis on larger enterprise deals and recurring revenue models drove substantial growth in both top-line revenue and profitability.\n",
      "============================================================\n",
      "Document ID: e6525611-0613-4ecd-8350-68111f86f873\n",
      "Similarity: 0.450479666931601\n",
      "Metadata: {'source': '..\\\\documents\\\\raw\\\\client-review-globalfinance.pdf', 'chunk_index': 5, 'source_name': 'client-review-globalfinance.pdf', 'document_chunk_index': 5, 'total_chunks_in_document': 24}\n",
      "Content: Financial Impact\n",
      "Category, 1 = Annual Impact. Category, 2 = Notes. Labor Cost Reducon, 1 = $2,268,000. Labor Cost Reducon, 2 = Eliminated 18 FTE posions through arion. Error Correcon Costs, 1 = $147,000. Error Correcon Costs, 2 = Reduced rework and compliance issues. Faster Loan Originaon, 1 = $380,000. Faster Loan Originaon, 2 = Increased volume & revenue per day. NeuralFlow AI Investment, 1 = ($425,000). NeuralFlow AI Investment, 2 = Annual plaorm cost. Net Annual Benefit, 1 = $2,370,000. Net Annual Benefit, 2 = ROI: 458%\n",
      "============================================================\n",
      "Document ID: dde4c544-4b26-441d-9333-f08ad2385665\n",
      "Similarity: 0.424310816058839\n",
      "Metadata: {'source': '..\\\\documents\\\\raw\\\\client-review-globalfinance.pdf', 'chunk_index': 0, 'source_name': 'client-review-globalfinance.pdf', 'document_chunk_index': 0, 'total_chunks_in_document': 24}\n",
      "Content: Meeng:\n",
      "Quarterly Business Review\n",
      "Client:\n",
      "GlobalFinance Corp\n",
      "Date:\n",
      "January 12, 2025\n",
      "Time:\n",
      "11:00 AM - 12:30 PM EST\n",
      "Locaon:\n",
      "GlobalFinance HQ / Virtual (Teams)\n",
      "Client Aendees:\n",
      "Richard Marnez (VP Operaons), Susan Park (Head of Loan Processing), James Chen\n",
      "(IT Director), Maria Gonzalez (Compliance Officer)\n",
      "NeuralFlow Aendees:\n",
      "Rachel Adams (CSM), Marcus Johnson (Soluons Architect), Tom Wilson\n",
      "(Account Execuve)\n",
      "Facilitator:\n",
      "Rachel Adams\n",
      "Notes:\n",
      "Rachel Adams\n"
     ]
    }
   ],
   "source": [
    "# query = \"What is the Q1 2025 revenue target?\"\n",
    "# query = \"When was NeuralFlow AI founded\"\n",
    "query = \"What ROI did GlobalFinance achieve?\"\n",
    "\n",
    "query_vector_store(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d617c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-docling-postgres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
