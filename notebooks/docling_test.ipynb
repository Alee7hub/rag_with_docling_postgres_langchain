{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6586c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b203b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72a0be",
   "metadata": {},
   "source": [
    "### ffmpeg is necessary for audio conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c04ed",
   "metadata": {},
   "source": [
    "Why do I need ffmpeg? It is a universal media converter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438a7bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFmpeg is installed and available in PATH.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def is_ffmpeg_installed():\n",
    "    try:\n",
    "        subprocess.run([\"ffmpeg\", \"-version\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        return False\n",
    "\n",
    "\n",
    "if is_ffmpeg_installed():\n",
    "    print(\"FFmpeg is installed and available in PATH.\")\n",
    "else:\n",
    "    print(\"FFmpeg is NOT installed or not in PATH.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15599d0",
   "metadata": {},
   "source": [
    "* If you have ffmpeg installed, you are good to go.\n",
    "* However, if you have it not installed, you should insall it first. It should also be available in your PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143f55c",
   "metadata": {},
   "source": [
    "### Audio converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18f23cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a test on only one example audio file for transcription\n",
    "\n",
    "from docling.document_converter import DocumentConverter, AudioFormatOption\n",
    "from docling.datamodel.pipeline_options import AsrPipelineOptions\n",
    "from docling.datamodel import asr_model_specs\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.asr_pipeline import AsrPipeline\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file if present\n",
    "\n",
    "def transcribe_audio(audio_path: str) -> str:\n",
    "    \"\"\"Transcribe audio file using Whisper ASR.\"\"\"\n",
    "\n",
    "    print(f\"\\nðŸŽ™ï¸  Transcribing: {Path(audio_path).name}\")\n",
    "    print(\"   This may take a moment on first run (downloading Whisper model)...\")\n",
    "\n",
    "    # Configure ASR pipeline with Whisper Turbo\n",
    "    pipeline_options = AsrPipelineOptions()\n",
    "    pipeline_options.asr_options = asr_model_specs.WHISPER_TURBO\n",
    "\n",
    "    # Create converter with ASR configuration\n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.AUDIO: AudioFormatOption(\n",
    "                pipeline_cls=AsrPipeline,\n",
    "                pipeline_options=pipeline_options,\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Transcribe\n",
    "    result = converter.convert(Path(audio_path).resolve())\n",
    "\n",
    "    # Export to markdown with timestamps\n",
    "    transcript = result.document.export_to_markdown()\n",
    "\n",
    "    return transcript\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Audio Transcription with Docling + Whisper\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Audio file to transcribe\n",
    "    audio_path = \"../documents/raw/founder_bio.mp3\"\n",
    "\n",
    "    print(f\"\\nInput: {audio_path}\")\n",
    "\n",
    "    try:\n",
    "        # Transcribe\n",
    "        transcript = transcribe_audio(audio_path)\n",
    "\n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRANSCRIPT OUTPUT\")\n",
    "        print(\"=\" * 60)\n",
    "        print(transcript[:800])  # Show first 800 characters\n",
    "        if len(transcript) > 800:\n",
    "            print(\"\\n... (truncated for display)\")\n",
    "\n",
    "        # Save to file\n",
    "        output_path = f\"../documents/processed/examples/output_{Path(audio_path).stem}.md\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcript)\n",
    "\n",
    "        print(f\"\\nâœ“ Full transcript saved to: {output_path}\")\n",
    "        print(f\"âœ“ Total length: {len(transcript)} characters\")\n",
    "\n",
    "        # Parse timestamp information\n",
    "        lines = transcript.split('\\n')\n",
    "        timestamp_lines = [line for line in lines if '[time:' in line]\n",
    "        if timestamp_lines:\n",
    "            print(f\"âœ“ Found {len(timestamp_lines)} timestamped segments\")\n",
    "            print(f\"\\nExample timestamp format:\")\n",
    "            print(f\"  {timestamp_lines[0][:80]}...\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nâœ— Error: FFmpeg not found!\")\n",
    "        print(\"\\nPlease install FFmpeg:\")\n",
    "        print(\"  Windows (Chocolatey): choco install ffmpeg\")\n",
    "        print(\"  Windows (Conda):      conda install -c conda-forge ffmpeg\")\n",
    "        print(\"  macOS:                brew install ffmpeg\")\n",
    "        print(\"  Linux:                apt-get install ffmpeg\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— Error: {e}\")\n",
    "        print(\"\\nMake sure:\")\n",
    "        print(\"  1. FFmpeg is installed and in PATH\")\n",
    "        print(\"  2. Audio file exists and is readable\")\n",
    "        print(\"  3. Audio format is supported (MP3, WAV, M4A, FLAC)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159058a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 12:25:19,910 - INFO - detected formats: [<InputFormat.AUDIO: 'audio'>]\n",
      "2025-11-21 12:25:19,918 - INFO - Going to convert document batch...\n",
      "2025-11-21 12:25:19,922 - INFO - Initializing pipeline for AsrPipeline with options hash 56c2b01f576cf4ca74241045cb5b4bbb\n",
      "2025-11-21 12:25:19,924 - INFO - artifacts-path: None\n",
      "2025-11-21 12:25:19,925 - INFO - accelerator_options: num_threads=4 device='auto' cuda_use_flash_attention2=False\n",
      "2025-11-21 12:25:19,927 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-21 12:25:19,928 - INFO - Available device for Whisper: cpu\n",
      "2025-11-21 12:25:19,929 - INFO - loading _NativeWhisperModel(turbo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Audio Transcription with Docling + Whisper\n",
      "============================================================\n",
      "\n",
      "Input: ../documents/raw/founder_bio.mp3\n",
      "\n",
      "ðŸŽ™ï¸  Transcribing: founder_bio.mp3\n",
      "   This may take a moment on first run (downloading Whisper model)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 12:25:33,524 - INFO - Processing document founder_bio.mp3\n",
      "2025-11-21 12:25:33,525 - INFO - start _build_document in AsrPipeline: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\documents\\raw\\founder_bio.mp3\n",
      "d:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 12:26:18,963 - INFO - Finished converting document founder_bio.mp3 in 59.06 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:10.200]  I am the CEO and co-founder of ABC company and I was born in Berlin and I\n",
      "[00:10.200 --> 00:19.580]  had around 2 million US dollars for investment in 2023\n",
      "\n",
      "============================================================\n",
      "TRANSCRIPT OUTPUT\n",
      "============================================================\n",
      "[time: 0.0-10.2]  I am the CEO and co-founder of ABC company and I was born in Berlin and I\n",
      "\n",
      "[time: 10.2-19.58]  had around 2 million US dollars for investment in 2023\n",
      "\n",
      "âœ“ Full transcript saved to: ../documents/processed/examples/output_founder_bio.md\n",
      "âœ“ Total length: 167 characters\n",
      "âœ“ Found 2 timestamped segments\n",
      "\n",
      "Example timestamp format:\n",
      "  [time: 0.0-10.2]  I am the CEO and co-founder of ABC company and I was born in B...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee5681",
   "metadata": {},
   "source": [
    "### Text converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ef9b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a test on three sample text docs\n",
    "\n",
    "def process_text_docs(file_path: str) -> dict:\n",
    "    \"\"\"Process a single document and return metadata.\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nðŸ“„ Processing: {Path(file_path).name}\")\n",
    "\n",
    "        # instantiate the converter\n",
    "        converter = DocumentConverter()\n",
    "\n",
    "        # Convert document\n",
    "        result = converter.convert(file_path)\n",
    "\n",
    "        # Export to markdown\n",
    "        markdown = result.document.export_to_markdown()\n",
    "\n",
    "        # Get document info\n",
    "        doc_info = {\n",
    "            'file': Path(file_path).name,\n",
    "            'format': Path(file_path).suffix,\n",
    "            'status': 'Success',\n",
    "            'markdown_length': len(markdown),\n",
    "            'preview': markdown[:200].replace('\\n', ' ')\n",
    "        }\n",
    "\n",
    "        # Save output\n",
    "        output_file = f\"../documents/processed/examples/output_{Path(file_path).stem}.md\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(markdown)\n",
    "\n",
    "        doc_info['output_file'] = output_file\n",
    "\n",
    "        print(f\"   âœ“ Converted successfully\")\n",
    "        print(f\"   âœ“ Output: {output_file}\")\n",
    "\n",
    "        return doc_info\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Error: {e}\")\n",
    "        return {\n",
    "            'file': Path(file_path).name,\n",
    "            'format': Path(file_path).suffix,\n",
    "            'status': 'Failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Multi-Format Document Processing with Docling\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # List of documents to process\n",
    "    documents = [\n",
    "        \"../documents/raw/technical-architecture-guide.pdf\",\n",
    "        \"../documents/raw/meeting-notes-2025-01-08.docx\",\n",
    "        \"../documents/raw/company-overview.md\",\n",
    "    ]\n",
    "\n",
    "    # Process all documents\n",
    "    results = []\n",
    "    for doc_path in documents:\n",
    "        result = process_text_docs(doc_path)\n",
    "        results.append(result)\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CONVERSION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for result in results:\n",
    "        status_icon = \"âœ“\" if result['status'] == 'Success' else \"âœ—\"\n",
    "        print(f\"{status_icon} {result['file']} ({result['format']})\")\n",
    "        if result['status'] == 'Success':\n",
    "            print(f\"   Length: {result['markdown_length']} chars\")\n",
    "            print(f\"   Preview: {result['preview']}...\")\n",
    "        else:\n",
    "            print(f\"   Error: {result.get('error', 'Unknown')}\")\n",
    "        print()\n",
    "\n",
    "    success_count = sum(1 for r in results if r['status'] == 'Success')\n",
    "    print(f\"Converted {success_count}/{len(results)} documents successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ec0ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 12:33:21,015 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Multi-Format Document Processing with Docling\n",
      "============================================================\n",
      "\n",
      "ðŸ“„ Processing: technical-architecture-guide.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 12:33:23,988 - INFO - Going to convert document batch...\n",
      "2025-11-21 12:33:23,991 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-11-21 12:33:24,099 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-21 12:33:24,122 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-11-21 12:33:24,175 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-21 12:33:24,227 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-11-21 12:33:24,556 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-11-21 12:33:24,559 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-11-21 12:33:25,832 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:25,874 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:25,945 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:25,946 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:27,178 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:27,195 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:27,196 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:27,312 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:27,385 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:33:27,386 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-11-21 12:33:27,700 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-11-21 12:33:27,716 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-21 12:33:29,673 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-21 12:33:30,617 - INFO - Processing document technical-architecture-guide.pdf\n",
      "2025-11-21 12:34:01,610 - INFO - Finished converting document technical-architecture-guide.pdf in 40.67 sec.\n",
      "2025-11-21 12:34:01,674 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-21 12:34:01,678 - INFO - Going to convert document batch...\n",
      "2025-11-21 12:34:01,678 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-11-21 12:34:01,682 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-11-21 12:34:01,684 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-11-21 12:34:01,685 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-11-21 12:34:01,712 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:34:01,757 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:34:01,758 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ Converted successfully\n",
      "   âœ“ Output: ../documents/processed/examples/output_technical-architecture-guide.md\n",
      "\n",
      "ðŸ“„ Processing: meeting-notes-2025-01-08.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2025-11-21 12:34:02,020 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:34:02,023 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:34:02,024 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:34:02,117 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:34:02,184 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-21 12:34:02,185 [RapidOCR] torch.py:54: Using D:\\Documents\\Learning\\Software_Engineering\\RAG\\langchain_docling_postgres\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-11-21 12:34:02,474 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-11-21 12:34:02,474 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-21 12:34:03,516 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-21 12:34:04,080 - INFO - Processing document meeting-notes-2025-01-08.docx\n",
      "2025-11-21 12:34:33,533 - INFO - Finished converting document meeting-notes-2025-01-08.docx in 31.89 sec.\n",
      "2025-11-21 12:34:33,588 - INFO - detected formats: [<InputFormat.MD: 'md'>]\n",
      "2025-11-21 12:34:33,590 - INFO - Going to convert document batch...\n",
      "2025-11-21 12:34:33,591 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-11-21 12:34:33,591 - INFO - Processing document company-overview.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ Converted successfully\n",
      "   âœ“ Output: ../documents/processed/examples/output_meeting-notes-2025-01-08.md\n",
      "\n",
      "ðŸ“„ Processing: company-overview.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 12:34:33,976 - INFO - Finished converting document company-overview.md in 0.40 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ Converted successfully\n",
      "   âœ“ Output: ../documents/processed/examples/output_company-overview.md\n",
      "\n",
      "============================================================\n",
      "CONVERSION SUMMARY\n",
      "============================================================\n",
      "âœ“ technical-architecture-guide.pdf (.pdf)\n",
      "   Length: 8699 chars\n",
      "   Preview: ## Technical Architecture Guide  NeuralFlow AI Platform v2.0  Document Version: 2.3 | Last Updated: December 15, 2024  Classification: Internal - Engineering Team  ## 1. System Overview  The NeuralFlo...\n",
      "\n",
      "âœ“ meeting-notes-2025-01-08.docx (.docx)\n",
      "   Length: 9338 chars\n",
      "   Preview: Meeting:  Product Strategy &amp; Roadmap Review  Date:  January 8, 2025  Time:  2:00 PM - 4:00 PM PT  Location:  Conference Room A  Attendees:  Sarah Chen (CTO), Michael Zhang (VP Product), Jennifer M...\n",
      "\n",
      "âœ“ company-overview.md (.md)\n",
      "   Length: 3102 chars\n",
      "   Preview: # NeuralFlow AI - Company Overview  ## About Us  NeuralFlow AI is a cutting-edge AI automation agency founded in 2023, specializing in intelligent workflow automation, natural language processing solu...\n",
      "\n",
      "Converted 3/3 documents successfully\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d6317",
   "metadata": {},
   "source": [
    "### Bring everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, converter for text documents\n",
    "def process_text_docs(raw_file_path: str):\n",
    "    \"\"\"Process a single document and return metadata.\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nðŸ“„ Processing: {Path(raw_file_path).name}\")\n",
    "\n",
    "        # instantiate the converter\n",
    "        converter = DocumentConverter()\n",
    "\n",
    "        # Convert document\n",
    "        result = converter.convert(raw_file_path)\n",
    "\n",
    "        # Export to markdown\n",
    "        markdown = result.document.export_to_markdown()\n",
    "\n",
    "        # Save output\n",
    "        output_file = f\"../documents/processed/{Path(raw_file_path).stem}.md\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(markdown)\n",
    "\n",
    "        print(f\"   âœ“ Converted successfully\")\n",
    "        print(f\"   âœ“ Output: {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Error: {e}\")\n",
    "        return {\n",
    "            'file': Path(raw_file_path).name,\n",
    "            'format': Path(raw_file_path).suffix,\n",
    "            'status': 'Failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Now, function for audio transcription    \n",
    "def process_audio_docs(audio_path: str):\n",
    "    \"\"\"Transcribe audio file using Whisper ASR.\"\"\"\n",
    "\n",
    "    print(f\"\\nðŸŽ™ï¸  Transcribing: {Path(audio_path).name}\")\n",
    "    print(\"   This may take a moment on first run (downloading Whisper model)...\")\n",
    "    print(f\"\\nInput: {audio_path}\")\n",
    "\n",
    "    # Configure ASR pipeline with Whisper Turbo\n",
    "    pipeline_options = AsrPipelineOptions()\n",
    "    pipeline_options.asr_options = asr_model_specs.WHISPER_TURBO\n",
    "\n",
    "    # Create converter with ASR configuration\n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.AUDIO: AudioFormatOption(\n",
    "                pipeline_cls=AsrPipeline,\n",
    "                pipeline_options=pipeline_options,\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Transcribe\n",
    "    result = converter.convert(Path(audio_path).resolve())\n",
    "\n",
    "    # Export to markdown with timestamps\n",
    "    transcript = result.document.export_to_markdown()\n",
    "\n",
    "    try:\n",
    "        # Display results\n",
    "        print(\"TRANSCRIPT OUTPUT:\")\n",
    "        print(transcript[:800])  # Show first 800 characters\n",
    "        if len(transcript) > 800:\n",
    "            print(\"\\n... (truncated for display)\")\n",
    "\n",
    "        # Save to file\n",
    "        output_path = f\"../documents/processed/{Path(audio_path).stem}.md\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcript)\n",
    "\n",
    "        print(f\"\\nâœ“ Full transcript saved to: {output_path}\")\n",
    "        print(f\"âœ“ Total length: {len(transcript)} characters\")\n",
    "\n",
    "        # Parse timestamp information\n",
    "        lines = transcript.split('\\n')\n",
    "        timestamp_lines = [line for line in lines if '[time:' in line]\n",
    "        if timestamp_lines:\n",
    "            print(f\"âœ“ Found {len(timestamp_lines)} timestamped segments\")\n",
    "            print(f\"\\nExample timestamp format:\")\n",
    "            print(f\"  {timestamp_lines[0][:80]}...\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nâœ— Error: FFmpeg not found!\")\n",
    "        print(\"\\nPlease install FFmpeg:\")\n",
    "        print(\"  Windows (Chocolatey): choco install ffmpeg\")\n",
    "        print(\"  Windows (Conda):      conda install -c conda-forge ffmpeg\")\n",
    "        print(\"  macOS:                brew install ffmpeg\")\n",
    "        print(\"  Linux:                apt-get install ffmpeg\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— Error: {e}\")\n",
    "        print(\"\\nMake sure:\")\n",
    "        print(\"  1. FFmpeg is installed and in PATH\")\n",
    "        print(\"  2. Audio file exists and is readable\")\n",
    "        print(\"  3. Audio format is supported (MP3, WAV, M4A, FLAC)\")\n",
    "\n",
    "def process_raw_documents(raw_documents_dir: str):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Multi-Format Document Processing with Docling\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # List of documents to process\n",
    "    directory = Path(raw_documents_dir)\n",
    "    documents = [str(file) for file in directory.iterdir() if file.is_file()]\n",
    "\n",
    "    # Process all documents\n",
    "    results = []\n",
    "    for doc_path in documents:\n",
    "        if Path(doc_path).suffix == '.mp3':\n",
    "            result = process_audio_docs(doc_path)\n",
    "        else:\n",
    "            result = process_text_docs(doc_path)\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_raw_documents(\"../documents/raw\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-docling-postgres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
